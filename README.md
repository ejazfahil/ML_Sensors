# ML Sensor: Person Detection Implementation

![Project Banner](images/banner.png)

<p align="center">
  <strong>Implementation of Harvard Edge ML-Sensors Research</strong><br>
  <em>Privacy-Preserving Edge AI for Person Detection</em>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/TensorFlow-2.13+-orange?logo=tensorflow" alt="TensorFlow"/>
  <img src="https://img.shields.io/badge/Python-3.10+-blue?logo=python" alt="Python"/>
  <img src="https://img.shields.io/badge/License-Educational-green" alt="License"/>
  <img src="https://img.shields.io/badge/Platform-Edge%20AI-purple" alt="Platform"/>
</p>

---

This project implements a complete **Machine Learning Sensor** for person detection, following the paradigm defined in the Harvard Edge research papers.

## ğŸ“š What is an ML Sensor?

An ML Sensor is a self-contained system that:
- Processes sensor data **on-device** using machine learning
- Outputs only **high-level insights** (not raw data)
- Provides a **simple, standardized interface**
- Enhances **privacy and security**
- Reduces **bandwidth and latency**

### Architecture Overview

![ML Sensor Architecture](images/architecture.png)

### Traditional IoT vs ML Sensor

![Comparison](images/comparison.png)

---

## ğŸ¯ What This Project Includes

### 1. Person Detection Model
- **Architecture:** MobileNetV1 (optimized for edge devices)
- **Input:** 96Ã—96 grayscale images
- **Output:** Binary classification (person detected: yes/no + confidence)

### 2. Edge Optimization
- **Quantization:** FP32 â†’ INT8 conversion
- **Model size reduction:** ~75%
- **Minimal accuracy degradation:** <2%

### 3. ML Sensor Simulation
- Complete sensor interface class
- I2C-compatible output format
- Preprocessing â†’ Inference â†’ Post-processing pipeline

### 4. Professional Datasheet
- Model characteristics
- Dataset nutrition label
- Performance analysis
- Hardware specifications

### Project Workflow

![Development Workflow](images/workflow.png)

---

## ğŸš€ Getting Started

### Prerequisites

```bash
pip install tensorflow>=2.13 tensorflow-datasets opencv-python pillow scikit-learn matplotlib seaborn tqdm
```

### Run the Notebook

```bash
jupyter notebook ML_Sensor_Person_Detection.ipynb
```

The notebook will:
1. Download and prepare the COCO dataset
2. Train a MobileNetV1 person detector
3. Quantize the model for edge deployment
4. Create an ML Sensor simulation
5. Generate a professional datasheet

**Estimated runtime:** 30-45 minutes (including training)

## ğŸ“Š Expected Results

- **Accuracy:** ~92-95%
- **Model Size:** ~0.5 MB (quantized)
- **Inference Time:** ~50-100 ms (CPU)
- **Data Transmitted:** ~100 bytes (vs 9KB raw image)
- **Privacy:** Images processed locally, never transmitted

## ğŸ“ Project Structure

```
ML Sensors CSProject/
â”œâ”€â”€ ML_Sensor_Person_Detection.ipynb    # Main notebook
â”œâ”€â”€ README.md                            # This file
â””â”€â”€ ml_sensor_data/                      # Generated during execution
    â”œâ”€â”€ dataset/                         # Downloaded images
    â”œâ”€â”€ models/                          # Trained models
    â”‚   â”œâ”€â”€ best_model.h5               # FP32 Keras model
    â”‚   â”œâ”€â”€ person_detector_fp32.tflite # FP32 TFLite
    â”‚   â””â”€â”€ person_detector_int8.tflite # INT8 quantized
    â””â”€â”€ results/                         # Visualizations & datasheet
        â”œâ”€â”€ sample_data.png
        â”œâ”€â”€ training_history.png
        â”œâ”€â”€ confusion_matrix.png
        â”œâ”€â”€ ml_sensor_demo.png
        â”œâ”€â”€ ml_sensor_datasheet.json
        â””â”€â”€ ml_sensor_datasheet.md
```

## ğŸ“ Learning Outcomes

By completing this project, you'll learn:

âœ… **TinyML Concepts:** Model quantization, edge optimization  
âœ… **Computer Vision:** Person detection, image preprocessing  
âœ… **Hardware-Software Co-Design:** Simulating sensor interfaces  
âœ… **ML Ethics:** Dataset transparency, privacy-preserving AI  
âœ… **Professional Documentation:** Creating ML sensor datasheets  

## ğŸ”¬ Key Concepts Demonstrated

### 1. Privacy by Architecture
```
Traditional IoT:  Camera â†’ Raw Image (9KB) â†’ Cloud â†’ Result
ML Sensor:        Camera â†’ On-Device ML â†’ Result (100 bytes)
```

### 2. Edge Optimization
- **Quantization:** Reduces model size with minimal accuracy loss
- **MobileNet:** Designed specifically for mobile/embedded devices
- **Preprocessing:** Grayscale conversion, resizing for efficiency

### 3. Standardized Interface
```json
{
  "sensor_id": "0x62",
  "person_detected": true,
  "confidence": 0.95,
  "inference_time_ms": 87,
  "timestamp": 1736125783
}
```

## ğŸ“– References

- [ML Sensors Whitepaper](https://arxiv.org/abs/2206.03266)
- [Datasheets for ML Sensors](https://arxiv.org/abs/2306.08848)
- [Harvard Edge ML-Sensors Repository](https://github.com/harvard-edge/ML-Sensors)
- [MLSensors.org](https://mlsensors.org/)

## ğŸ› ï¸ Next Steps

### Hardware Deployment
Deploy the quantized model to:
- Raspberry Pi 4 with camera module
- Arduino Nano 33 BLE Sense
- ESP32-CAM module

### Model Improvements
- Collect domain-specific data
- Implement advanced augmentation
- Try different architectures (EfficientNet-Lite, etc.)

### Advanced Features
- Multi-person detection
- Activity recognition
- Real-time video processing
- Integration with IoT systems

### Research Extensions
- Federated learning for privacy-preserving updates
- Adversarial robustness testing
- Energy consumption profiling
- Benchmarking against other TinyML frameworks

## ğŸ¤ Contributing

This is an educational project. Feel free to:
- Experiment with different models
- Improve the datasheet format
- Add new features
- Share your results!

## ğŸ“œ License

This project is for educational purposes, following the Harvard Edge ML-Sensors research.

## ğŸ™ Acknowledgments

- **Harvard Edge Team** for the ML Sensors paradigm
- **TensorFlow Team** for TFLite and quantization tools
- **COCO Dataset** for training data

---

**Happy Learning! ğŸ‰**

*For questions or issues, refer to the comprehensive guide in the artifacts folder.*
